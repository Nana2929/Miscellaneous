{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT3o5oW70vPm"
   },
   "source": [
    "## **HYPERPARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MOqYagBhQBmW"
   },
   "outputs": [],
   "source": [
    "# training arguments:\n",
    "# https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "\n",
    "base_model = 'bert-base-chinese'\n",
    "batchsize = 12\n",
    "prompt_len = n_tokens = 12\n",
    "lr = 5e-4\n",
    "epochs = 20\n",
    "scheduler_type = \"linear\"\n",
    "wd = 0.005\n",
    "warmup_ratio = 0.1\n",
    "myseed = 1126\n",
    "nclass = 19\n",
    "TESTSIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoOL6HpA9fUY"
   },
   "source": [
    "## Loading dataset & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BSj1o00M9TQy"
   },
   "outputs": [],
   "source": [
    "#!pip -q install transformers\n",
    "#!pip -q install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "24FbYd8T7wht"
   },
   "outputs": [],
   "source": [
    "# Server Paths \n",
    "# ..data/avo727/PromptTuning/CWNdata/Sean_PT2_encoded_dataset\n",
    "maindir = \"/mnt/md0/data/avo727/PromptTuning\"\n",
    "datadir = f\"{maindir}/CWN_data\"\n",
    "preddir = f\"{maindir}/model_predictions\"\n",
    "datasetdir= f\"{maindir}/CWNdata/PT2_allchoice_encoded_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tCOFpaDT7y4-"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datasets import Dataset, load_metric\n",
    "import datasets\n",
    "from transformers import AutoModelForMultipleChoice, BertTokenizerFast\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "encoded_dataset = datasets.load_from_disk(datasetdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['type_class', 'eng word', 'word', 'pos', 'instance', 'src', 'dot_type_2', 'dot_type_1', 'label', 'zh_type_class', 'zh_dot_type', 'zh_dot_type_2', 'zh_dot_gloss', 'is_one_ans', 'numchoices', 'class_selector', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 490\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['type_class', 'eng word', 'word', 'pos', 'instance', 'src', 'dot_type_2', 'dot_type_1', 'label', 'zh_type_class', 'zh_dot_type', 'zh_dot_type_2', 'zh_dot_gloss', 'is_one_ans', 'numchoices', 'class_selector', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 123\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OBG49-59mje"
   },
   "source": [
    "## Data collator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "x1vAyugiFfz5"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bx8G7ey-ErQ_"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    allchoice version: 全數攤平送往model內部處理（不經unflatten，確保傳輸numchoices）\n",
    "    \"\"\"\n",
    "    tokenizer = tokenizer\n",
    "    padding, trunc = True, True\n",
    "    max_length =  None\n",
    "    pad_to_multiple_of = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        pin_label = True if \"label\" in features[0].keys() else False\n",
    "        accepted_keys = [\"input_ids\", \"attention_mask\", \"label\", \n",
    "                         \"token_type_ids\", 'class_selector', 'numchoices']\n",
    "        batch_size = len(features)\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        numchoices = [feature.pop('numchoices') for feature in features]\n",
    "        seq_classes = [feature.pop('class_selector') for feature in features]\n",
    "        \n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items() if k in accepted_keys} \n",
    "                               for i in range(nc)] for feature, nc in zip(features, numchoices)]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding= \"longest\",\n",
    "            max_length= self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # flattened \n",
    "        batch = {k: v for k, v in batch.items() if k in accepted_keys}\n",
    "        # print(len(batch['input_ids'])) # print(sum([len(x) for x in seq_classes])) # should match \n",
    "        batch[\"class_selector\"] = torch.tensor(sum(seq_classes, [])) # flattening list of lists\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        batch[\"numchoices\"] = torch.tensor(numchoices, dtype=torch.int64)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a4Bt1_5eNfGx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('input_ids', torch.Size([1014, 93])),\n",
       " ('token_type_ids', torch.Size([1014, 93])),\n",
       " ('attention_mask', torch.Size([1014, 93])),\n",
       " ('class_selector', torch.Size([1014])),\n",
       " ('labels', torch.Size([490])),\n",
       " ('numchoices', torch.Size([490]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANGE = len(encoded_dataset['train'])\n",
    "features = [{k: v for k, v in encoded_dataset[\"train\"][i].items()} for i in range(RANGE)]\n",
    "batch = DataCollatorForMultipleChoice()(features)\n",
    "[(k, v.shape) for k, v in batch.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RM-NkD1KEkL"
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tHxdTitOEX_z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import MultipleChoiceModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNwk40KEJdsE",
    "outputId": "4574943d-477d-4a92-813e-569a695d3db8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb\n",
    "# import wandb\n",
    "# # wandb.login() # 87f450abf77ebb78b46b7cf9516b1bad9d6ef540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the run: 0316-1919_RPBert\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timeprefix = now.strftime(\"%m%d-%H%M\")\n",
    "runname = f'{timeprefix}_RPBert'\n",
    "print('Name of the run:', runname)\n",
    "# wandb.init(project=\"prompt_tuning_rp_v2\", \n",
    "#            name = runname,\n",
    "#            tags=[\"prompt-tuning\", \"regular-polysemy\"],\n",
    "#            group=\"bert\")\n",
    "# wandb.config.update({'n_tokens':n_tokens})\n",
    "\n",
    "# # https://docs.wandb.ai/guides/integrations/huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iOQYZsmz8q6"
   },
   "source": [
    "## freezed bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRkC1Zg6EnBM",
    "outputId": "f8e413b9-7499-4d5a-e442-8c87c43e815b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertPromptForMultipleChoice: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertPromptForMultipleChoice were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['prefix_encoder.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'classifier.weight', 'embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** total param is 175873\n",
      "** train bert? False\n"
     ]
    }
   ],
   "source": [
    "from PromptTuningBERT_allchoice import BertPromptForMultipleChoice\n",
    "config = {\n",
    "    'n_tokens': prompt_len ,\n",
    "    'n_class': nclass,\n",
    "    'train_bert': False,\n",
    "    'to_debug': False,\n",
    "    'device': 'cuda'\n",
    "} # model forwarding creates new tensors out of the original inputs, so device shall be specified beforehand\n",
    "model = BertPromptForMultipleChoice.from_pretrained(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "NRRNyl1RmzcP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPromptForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (prefix_encoder): Embedding(19, 9216)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7176768779754639\n",
      "1.6829617023468018\n",
      "1.292707920074463\n",
      "0.8405603170394897\n",
      "0.3639366626739502\n",
      "0.28752052783966064\n",
      "0.09441858530044556\n",
      "0.1253374069929123\n",
      "0.05292954668402672\n",
      "0.021745776757597923\n"
     ]
    }
   ],
   "source": [
    "import torch.nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "loader = DataLoader(encoded_dataset['train'], \n",
    "                    shuffle=False, \n",
    "                    collate_fn=DataCollatorForMultipleChoice(), \n",
    "                    batch_size=batchsize)\n",
    "loss_vec = []\n",
    "for i in range(10):# epochs = 20 \n",
    "    for batch in loader:  \n",
    "        batch = {k: batch[k].to('cuda') for k in batch}\n",
    "        optimizer.zero_grad()\n",
    "        out = model(**batch)\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_vec.append(loss.item())\n",
    "    print(loss_vec[-1])\n",
    "        #writer.add_scalar(\"Loss/train\", loss.item(), step_i)      \n",
    "        #step_i += 1\n",
    "# print(loss_vec)\n",
    "# prompts: torch.Size([25, 12, 768]) # totalsentnumber, prompt_len, hidden_dim\n",
    "# totalsentnumber: sum(numchoice for numchoice in this batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1bd897d1c0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(loss_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6CfXCc7-ezOl"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "args = TrainingArguments(\n",
    "    runname, \n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batchsize,\n",
    "    per_device_eval_batch_size=batchsize,\n",
    "    num_train_epochs=epochs,\n",
    "    gradient_accumulation_steps=1, \n",
    "    weight_decay=wd,\n",
    "    warmup_ratio = warmup_ratio,\n",
    "    lr_scheduler_type=scheduler_type,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    # report_to=\"wandb\",\n",
    "    load_best_model_at_end = False, # True: use eval loss\n",
    "    seed = myseed # seeding!!!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "o4UZrmP0qOGo"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_dict):\n",
    "    # re_logits_mapping[nc] = reshaped_logits\n",
    "    # 把三個的挑出來做成一組predictions matrix \n",
    "    # 兩個的挑出來做另一組 matrix\n",
    "    print(typeof(logits_dict))\n",
    "    print(logits_dict)\n",
    "    # predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return #{'accuracy': (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "QzpegHcMqFT-"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OkM1jDjnqJHI",
    "outputId": "4c8324d1-8edd-45c4-be45-6ba70c578034"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: dot_type_1, zh_dot_type_2, zh_type_class, dot_type_2, pos, word, type_class, eng word, zh_dot_type, instance, zh_dot_gloss, is_one_ans, src.\n",
      "/home/avo727/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 490\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 820\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnana2929\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/md0/data/avo727/PromptTuning/runs/wandb/run-20220316_193246-3hd2rs4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nana2929/huggingface/runs/3hd2rs4n\" target=\"_blank\">0316-1919_RPBert</a></strong> to <a href=\"https://wandb.ai/nana2929/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 42/820 00:05 < 01:46, 7.30 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: dot_type_1, zh_dot_type_2, zh_type_class, dot_type_2, pos, word, type_class, eng word, zh_dot_type, instance, zh_dot_gloss, is_one_ans, src.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 123\n",
      "  Batch size = 12\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# bert freeze version \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1455\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1459\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:1565\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1563\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 1565\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, epoch, metrics)\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2208\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2205\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2207\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2208\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2218\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   2219\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   2220\u001b[0m     speed_metrics(\n\u001b[1;32m   2221\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2225\u001b[0m     )\n\u001b[1;32m   2226\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2382\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2379\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   2381\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 2382\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   2385\u001b[0m     xm\u001b[38;5;241m.\u001b[39mmark_step()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2612\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_loss_only:\n\u001b[1;32m   2610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (loss, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2612\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mnested_detach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(logits) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2614\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py:151\u001b[0m, in \u001b[0;36mnested_detach\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetach `tensors` (even if it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a nested list/tuple of tensors).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_detach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py:151\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetach `tensors` (even if it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a nested list/tuple of tensors).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_detach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/trainer_pt_utils.py:152\u001b[0m, in \u001b[0;36mnested_detach\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_detach(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "# bert freeze version \n",
    "trainer.train()\n",
    "# solution 1. 不要用trainer，寫manual training loop \n",
    "# pros: simplicity, controllable cons: hyperparams and scheduler feature will need to be added by ourselves\n",
    "# solution 2. 改trainer.py裡的程式碼，修正prediction_step()\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py#L2445\n",
    "# pros: keeping the hyperparams api simplicity cons: 可能還有一堆dependencies要修 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxJFRzmGmI2y"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEijr2DzmIZi"
   },
   "outputs": [],
   "source": [
    "print(\"Evaluating...\")\n",
    "import numpy as np\n",
    "# timeprefix = 0312-1300\n",
    "best_ckpt = 'checkpoint-1064'\n",
    "best_ckpt_path = f'{runname}/{best_ckpt}'\n",
    "model = BertPromptForMultipleChoice.from_pretrained(best_ckpt_path, config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(),\n",
    "    compute_metrics=compute_metrics,)\n",
    "\n",
    "PredOutput = trainer.predict(\n",
    "    test_dataset = encoded_dataset[\"test\"])\n",
    "    \n",
    "labels = PredOutput.label_ids\n",
    "print('acc:', compute_metrics((PredOutput.predictions, labels)))\n",
    "\n",
    "\n",
    "logits_path = f\"{preddir}/{timeprefix}_{best_ckpt}_logits\"\n",
    "preds_path = f\"{preddir}/{timeprefix}_{best_ckpt}_predictions\"\n",
    "labels_path = f\"{preddir}/{timeprefix}_{best_ckpt}_labels\" # save because the dataset is shuffled\n",
    "preds = np.argmax(PredOutput.predictions, axis=-1)\n",
    "\n",
    "np.save(logits_path, PredOutput.predictions)\n",
    "np.save(preds_path, preds)\n",
    "np.save(labels_path,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGWccY2hzKFf"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qlCuHSXvFAeB"
   ],
   "name": "6-ptv2-experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
