{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT3o5oW70vPm"
   },
   "source": [
    "## **HYPERPARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MOqYagBhQBmW"
   },
   "outputs": [],
   "source": [
    "# training arguments:\n",
    "# https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "\n",
    "base_model = 'bert-base-chinese'\n",
    "batchsize = 6\n",
    "prompt_len = n_tokens = 12\n",
    "lr = 5e-4\n",
    "epochs = 20\n",
    "scheduler_type = \"linear\"\n",
    "wd = 0.005\n",
    "warmup_ratio = 0.1\n",
    "myseed = 1126\n",
    "\n",
    "nclass = 19\n",
    "numchoices = 2\n",
    "TESTSIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoOL6HpA9fUY"
   },
   "source": [
    "## Loading dataset & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BSj1o00M9TQy"
   },
   "outputs": [],
   "source": [
    "!pip -q install transformers\n",
    "!pip -q install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "24FbYd8T7wht"
   },
   "outputs": [],
   "source": [
    "# Server Paths \n",
    "# ..data/avo727/PromptTuning/CWNdata/Sean_PT2_encoded_dataset\n",
    "maindir = \"/mnt/md0/data/avo727/PromptTuning\"\n",
    "datadir = f\"{maindir}/CWN_data\"\n",
    "preddir = f\"{maindir}/model_predictions\"\n",
    "###########################\n",
    "datasetdir= f\"{maindir}/CWNdata/Sean_PT2_encoded_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tCOFpaDT7y4-"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from datasets import Dataset, load_metric\n",
    "import datasets\n",
    "from transformers import AutoModelForMultipleChoice, BertTokenizerFast\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "encoded_dataset = datasets.load_from_disk(datasetdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['type_class', 'eng word', 'word', 'pos', 'instance', 'src', 'dot_type_2', 'dot_type_1', 'label', 'zh_type_class', 'zh_dot_type', 'zh_dot_type_2', 'zh_dot_gloss', 'is_2choice', 'is_one_ans', 'class_selector', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 455\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['type_class', 'eng word', 'word', 'pos', 'instance', 'src', 'dot_type_2', 'dot_type_1', 'label', 'zh_type_class', 'zh_dot_type', 'zh_dot_type_2', 'zh_dot_gloss', 'is_2choice', 'is_one_ans', 'class_selector', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 114\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlCuHSXvFAeB"
   },
   "source": [
    "## Seeding (skipped, seed in ðŸ¤— trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "7Bi7-KwcFB0B",
    "outputId": "35cb3f7e-3bcb-42e2-eafa-a9ad4204c0c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef seeding(myseed):\\n  torch.manual_seed(myseed)\\n  torch.cuda.manual_seed(myseed)\\n  torch.cuda.manual_seed_all(myseed)\\n  torch.backends.cudnn.benchmark = False\\n  torch.backends.cudnn.deterministic = True\\n  random.seed(myseed)\\n  np.random.seed(myseed)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def seeding(myseed):\n",
    "  torch.manual_seed(myseed)\n",
    "  torch.cuda.manual_seed(myseed)\n",
    "  torch.cuda.manual_seed_all(myseed)\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  random.seed(myseed)\n",
    "  np.random.seed(myseed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OBG49-59mje"
   },
   "source": [
    "## Data collator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x1vAyugiFfz5"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bx8G7ey-ErQ_"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "    tokenizer = tokenizer\n",
    "    padding, trunc = True, True\n",
    "    max_length =  None\n",
    "    pad_to_multiple_of = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        pin_label = True if \"label\" in features[0].keys() else False\n",
    "        accepted_keys = [\"input_ids\", \"attention_mask\", \"label\", \"token_type_ids\", 'class_selector']\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        seq_classes = [feature.pop('class_selector') for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items() if k in accepted_keys} \n",
    "                               for i in range(num_choices)] for feature in features]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding= \"longest\",\n",
    "            max_length= self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # filtering\n",
    "        # Un-flatten\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items() if k in accepted_keys}\n",
    "        \n",
    "        # prompt selectors\n",
    "        batch[\"class_selector\"] = torch.tensor(seq_classes)\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "  \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "a4Bt1_5eNfGx"
   },
   "outputs": [],
   "source": [
    "RANGE = len(encoded_dataset['train'])\n",
    "features = [{k: v for k, v in encoded_dataset[\"train\"][i].items()} for i in range(RANGE)]\n",
    "batch = DataCollatorForMultipleChoice()(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Xj3Lt-hilmg0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(RANGE):\\n    print([len(encoded_dataset[\"train\"][i][\\'input_ids\\'][j]) for j in range(numchoices)])\\n    a_set_of_inputs = [tokenizer.decode(batch[\"input_ids\"][i][j].tolist()) for j in range(numchoices)]\\n    # batch[\"input_ids\"].shape: (455, 2, 300), (batch_size, numchoice, max_length)\\n    # print([len(x) for x in a_set_of_inputs]) # not 300 because of extra spaces, and [PAD] is considered 5 words instead of one token\\n    print(\\'--------\\')\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(RANGE):\n",
    "    print([len(encoded_dataset[\"train\"][i]['input_ids'][j]) for j in range(numchoices)])\n",
    "    a_set_of_inputs = [tokenizer.decode(batch[\"input_ids\"][i][j].tolist()) for j in range(numchoices)]\n",
    "    # batch[\"input_ids\"].shape: (455, 2, 300), (batch_size, numchoice, max_length)\n",
    "    # print([len(x) for x in a_set_of_inputs]) # not 300 because of extra spaces, and [PAD] is considered 5 words instead of one token\n",
    "    print('--------')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RM-NkD1KEkL"
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tHxdTitOEX_z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers.modeling_outputs import MultipleChoiceModelOutput\n",
    "\n",
    "from PromptTuningBERT import BertPromptForMultipleChoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JNwk40KEJdsE",
    "outputId": "4574943d-477d-4a92-813e-569a695d3db8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/avo727/miniconda3/lib/python3.9/site-packages (0.12.11)\n",
      "Requirement already satisfied: PyYAML in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setproctitle in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (1.2.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (1.5.7)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /home/avo727/miniconda3/lib/python3.9/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/avo727/miniconda3/lib/python3.9/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/avo727/miniconda3/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/avo727/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/avo727/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/avo727/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/avo727/miniconda3/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /home/avo727/miniconda3/lib/python3.9/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnana2929\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login() # 87f450abf77ebb78b46b7cf9516b1bad9d6ef540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the run: 0312-1300_RPBert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/md0/data/avo727/PromptTuning/runs/wandb/run-20220312_130050-2iqdlkzb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nana2929/prompt_tuning_rp_v2/runs/2iqdlkzb\" target=\"_blank\">0312-1300_RPBert</a></strong> to <a href=\"https://wandb.ai/nana2929/prompt_tuning_rp_v2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timeprefix = now.strftime(\"%m%d-%H%M\")\n",
    "runname = f'{timeprefix}_RPBert'\n",
    "print('Name of the run:', runname)\n",
    "wandb.init(project=\"prompt_tuning_rp_v2\", \n",
    "           name = runname,\n",
    "           tags=[\"prompt-tuning\", \"regular-polysemy\"],\n",
    "           group=\"bert\")\n",
    "wandb.config.update({'n_tokens':n_tokens})\n",
    "# https://docs.wandb.ai/guides/integrations/huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iOQYZsmz8q6"
   },
   "source": [
    "## freezed bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRkC1Zg6EnBM",
    "outputId": "f8e413b9-7499-4d5a-e442-8c87c43e815b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertPromptForMultipleChoice: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertPromptForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertPromptForMultipleChoice were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['embeddings.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'prefix_encoder.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** total param is 175873\n",
      "** train bert? False\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'n_tokens':prompt_len ,\n",
    "    'n_class':nclass,\n",
    "    'numchoices': numchoices,\n",
    "    'train_bert': False\n",
    "}\n",
    "model = BertPromptForMultipleChoice.from_pretrained(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NRRNyl1RmzcP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPromptForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       "  (prefix_encoder): Embedding(19, 9216)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6CfXCc7-ezOl"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "args = TrainingArguments(\n",
    "    runname, \n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batchsize,\n",
    "    per_device_eval_batch_size=batchsize,\n",
    "    num_train_epochs=epochs,\n",
    "    gradient_accumulation_steps=1, \n",
    "    weight_decay=wd,\n",
    "    warmup_ratio = warmup_ratio,\n",
    "    lr_scheduler_type=scheduler_type,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    report_to=\"wandb\",\n",
    "    load_best_model_at_end = False, # True: use eval loss\n",
    "    seed = myseed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "o4UZrmP0qOGo"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy': (preds == label_ids).astype(np.float32).mean().item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QzpegHcMqFT-"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OkM1jDjnqJHI",
    "outputId": "4c8324d1-8edd-45c4-be45-6ba70c578034"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "/home/avo727/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 455\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1520\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1520' max='1520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1520/1520 01:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.720685</td>\n",
       "      <td>0.438596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.697960</td>\n",
       "      <td>0.508772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>0.715204</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.830253</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.652400</td>\n",
       "      <td>0.704666</td>\n",
       "      <td>0.587719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.694773</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.721976</td>\n",
       "      <td>0.614035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>0.812229</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.574600</td>\n",
       "      <td>0.762866</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.527900</td>\n",
       "      <td>0.794231</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.842332</td>\n",
       "      <td>0.640351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.450600</td>\n",
       "      <td>0.849754</td>\n",
       "      <td>0.675439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.811362</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.869877</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.952223</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>0.961116</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>1.020126</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>0.941951</td>\n",
       "      <td>0.675439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.944960</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-76\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-76/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-76/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-76/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-76/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-152\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-152/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-152/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-152/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-152/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-228\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-228/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-228/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-228/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-228/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-304\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-304/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-304/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-304/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-304/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-380\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-380/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-380/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-380/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-380/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-456\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-456/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-456/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-456/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-456/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-532\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-532/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-532/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-532/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-532/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-608\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-608/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-608/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-608/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-608/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-684\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-684/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-684/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-684/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-684/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-760\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-760/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-760/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-760/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-760/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-836\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-836/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-836/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-836/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-836/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-912\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-912/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-912/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-912/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-912/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-988\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-988/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-988/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-988/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-988/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1064\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1064/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1064/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1064/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1064/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1140\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1140/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1140/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1140/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1140/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1216\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1216/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1216/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1216/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1216/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1292\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1292/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1292/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1292/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1292/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1368\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1368/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1368/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1368/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1368/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1444\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1444/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1444/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1444/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1444/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 114\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to 0312-1300_RPBert/checkpoint-1520\n",
      "Configuration saved in 0312-1300_RPBert/checkpoint-1520/config.json\n",
      "Model weights saved in 0312-1300_RPBert/checkpoint-1520/pytorch_model.bin\n",
      "tokenizer config file saved in 0312-1300_RPBert/checkpoint-1520/tokenizer_config.json\n",
      "Special tokens file saved in 0312-1300_RPBert/checkpoint-1520/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from 0312-1300_RPBert/checkpoint-456 (score: 0.6947730779647827).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1520, training_loss=0.5190150612278989, metrics={'train_runtime': 61.4679, 'train_samples_per_second': 148.045, 'train_steps_per_second': 24.728, 'total_flos': 615881950804344.0, 'train_loss': 0.5190150612278989, 'epoch': 20.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert freeze version \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxJFRzmGmI2y"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "mEijr2DzmIZi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file 0312-1300_RPBert/checkpoint-1064/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-chinese\",\n",
      "  \"architectures\": [\n",
      "    \"BertPromptForMultipleChoice\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file 0312-1300_RPBert/checkpoint-1064/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertPromptForMultipleChoice.\n",
      "\n",
      "All the weights of BertPromptForMultipleChoice were initialized from the model checkpoint at 0312-1300_RPBert/checkpoint-1064.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertPromptForMultipleChoice for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertPromptForMultipleChoice.forward` and have been ignored: zh_dot_gloss, instance, zh_dot_type_2, eng word, dot_type_2, src, type_class, dot_type_1, is_one_ans, word, __index_level_0__, pos, zh_type_class, zh_dot_type, is_2choice.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 114\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** total param is 175873\n",
      "** train bert? False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: {'accuracy': 0.7105262875556946}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating...\")\n",
    "import numpy as np\n",
    "# timeprefix = 0312-1300\n",
    "best_ckpt = 'checkpoint-1064'\n",
    "best_ckpt_path = f'{runname}/{best_ckpt}'\n",
    "model = BertPromptForMultipleChoice.from_pretrained(best_ckpt_path, config)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(),\n",
    "    compute_metrics=compute_metrics,)\n",
    "\n",
    "PredOutput = trainer.predict(\n",
    "    test_dataset = encoded_dataset[\"test\"])\n",
    "    \n",
    "labels = PredOutput.label_ids\n",
    "print('acc:', compute_metrics((PredOutput.predictions, labels)))\n",
    "\n",
    "\n",
    "logits_path = f\"{preddir}/{timeprefix}_{best_ckpt}_logits\"\n",
    "preds_path = f\"{preddir}/{timeprefix}_{best_ckpt}_predictions\"\n",
    "labels_path = f\"{preddir}/{timeprefix}_{best_ckpt}_labels\" # save because the dataset is shuffled\n",
    "preds = np.argmax(PredOutput.predictions, axis=-1)\n",
    "\n",
    "np.save(logits_path, PredOutput.predictions)\n",
    "np.save(preds_path, preds)\n",
    "np.save(labels_path,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nGWccY2hzKFf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–â–ƒâ–„â–‚â–…â–†â–†â–†â–†â–…â–‡â–†â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>eval/loss</td><td>â–‚â–â–â–„â–â–â–‚â–„â–‚â–ƒâ–„â–„â–„â–„â–…â–‡â–‡â–ˆâ–†â–†</td></tr><tr><td>eval/runtime</td><td>â–ƒâ–â–â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–…â–†â–…â–‡â–‡â–‡â–†â–ˆ</td></tr><tr><td>eval/samples_per_second</td><td>â–†â–ˆâ–ˆâ–†â–ˆâ–‡â–†â–‡â–†â–†â–ˆâ–†â–„â–ƒâ–„â–‚â–‚â–‚â–ƒâ–</td></tr><tr><td>eval/steps_per_second</td><td>â–†â–ˆâ–ˆâ–†â–ˆâ–‡â–†â–‡â–†â–†â–ˆâ–†â–„â–ƒâ–„â–‚â–‚â–‚â–ƒâ–</td></tr><tr><td>train/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/learning_rate</td><td>â–…â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–…â–†â–…â–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>train/train_loss</td><td>â–</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/train_steps_per_second</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66667</td></tr><tr><td>eval/loss</td><td>0.94496</td></tr><tr><td>eval/runtime</td><td>0.2117</td></tr><tr><td>eval/samples_per_second</td><td>538.526</td></tr><tr><td>eval/steps_per_second</td><td>89.754</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>1520</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3553</td></tr><tr><td>train/total_flos</td><td>615881950804344.0</td></tr><tr><td>train/train_loss</td><td>0.51902</td></tr><tr><td>train/train_runtime</td><td>61.4679</td></tr><tr><td>train/train_samples_per_second</td><td>148.045</td></tr><tr><td>train/train_steps_per_second</td><td>24.728</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">0312-1300_RPBert</strong>: <a href=\"https://wandb.ai/nana2929/prompt_tuning_rp_v2/runs/2iqdlkzb\" target=\"_blank\">https://wandb.ai/nana2929/prompt_tuning_rp_v2/runs/2iqdlkzb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220312_130050-2iqdlkzb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qlCuHSXvFAeB"
   ],
   "name": "6-ptv2-experiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
